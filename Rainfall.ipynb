{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a457160b",
      "metadata": {
        "id": "a457160b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from tabulate import tabulate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vTIgPLLofvMw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vTIgPLLofvMw",
        "outputId": "7cc4132c-f5a2-402c-a39c-002e20ed80a0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset/dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KbqEcKHK-_3Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "KbqEcKHK-_3Z",
        "outputId": "3695b116-04cf-4762-f4b2-90ecd0965906"
      },
      "outputs": [],
      "source": [
        "rainfall_classification = []\n",
        "\n",
        "for i in df['rainfall']:\n",
        "    if(i==0):\n",
        "        rainfall_classification.append(0)\n",
        "    elif(i>0 and i<2.5):\n",
        "        rainfall_classification.append(1)\n",
        "    elif(i>=2.5 and i<7.5):\n",
        "        rainfall_classification.append(2)\n",
        "    elif(i>=7.5 and i<35.5):\n",
        "        rainfall_classification.append(3)\n",
        "    elif(i>=35.5 and i<64.4):\n",
        "        rainfall_classification.append(4)\n",
        "    elif(i>=64.4 and i<124.4):\n",
        "        rainfall_classification.append(5)\n",
        "    else:\n",
        "        rainfall_classification.append(6)\n",
        "\n",
        "df['rainfall_classification'] = rainfall_classification\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y2aro1xif5w4",
      "metadata": {
        "id": "Y2aro1xif5w4"
      },
      "outputs": [],
      "source": [
        "# Extract input features and target variable\n",
        "X = df[['date', 'month', 'year', 'temperature', 'specific humidity', 'relative humidity', 'surface pressure', 'wind speed', 'wind direction']]\n",
        "y = df['rainfall_classification']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#y_test = y_test.tolist()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "49831582",
      "metadata": {},
      "source": [
        "### AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f7b90a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def AB(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 1],\n",
        "        'base_estimator__max_depth': [1, 2, 3],\n",
        "        'base_estimator__max_features': [None, 'sqrt', 'log2']\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    adaboost_clf = AdaBoostClassifier(base_estimator=base_estimator, algorithm='SAMME.R', random_state=42)\n",
        "    grid_search = GridSearchCV(adaboost_clf, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator from the GridSearchCV\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    predictions = best_estimator.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nAdaBoost :\\n\")\n",
        "\n",
        "data = [AB(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ea7e92e3",
      "metadata": {},
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560535fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def DT(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    parameters = {\n",
        "        'criterion': ['gini', 'entropy'],\n",
        "        'max_depth': [None, 1, 2, 3, 4, 5],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'max_features': [None, 'sqrt', 'log2']\n",
        "    }\n",
        "\n",
        "    dt_classifier = DecisionTreeClassifier()\n",
        "    cv_method = StratifiedKFold(n_splits=10)\n",
        "    grid_search = GridSearchCV(dt_classifier, parameters, cv=cv_method, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    model = DecisionTreeClassifier(**grid_search.best_params_)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the training data and compute accuracy\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nDecision Tree :\\n\")\n",
        "\n",
        "data = [DT(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "657aa3ec",
      "metadata": {},
      "source": [
        "### Extra Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68806ccf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ET(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    parameters = {'n_estimators': [10, 50, 100],\n",
        "                   'max_features': ['auto', 'sqrt', 'log2'],\n",
        "                   'max_depth': [3, 5, 7, None],\n",
        "                   'min_samples_split': [2, 5, 10],\n",
        "                   'min_samples_leaf': [1, 2, 4],\n",
        "                   'criterion': ['gini', 'entropy']}\n",
        "\n",
        "    lr = ExtraTreesClassifier()\n",
        "    cv = StratifiedKFold(n_splits=5)\n",
        "    grid_search = GridSearchCV(lr, parameters, cv=cv, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator from the GridSearchCV\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    predictions = best_estimator.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nExtra Tree :\\n\")\n",
        "\n",
        "data = [ET(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e7fa94de",
      "metadata": {},
      "source": [
        "### Gaussian NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b13aad",
      "metadata": {},
      "outputs": [],
      "source": [
        "def GNB(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    parameters = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "\n",
        "    nb = GaussianNB()\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(nb, parameters, cv=cv, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator from the GridSearchCV\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    predictions = best_estimator.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nGaussian NB:\\n\")\n",
        "\n",
        "data = [GNB(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c759106f",
      "metadata": {},
      "source": [
        "### Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ddbdd5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def GB(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    parameters = {'learning_rate': [0.01, 0.1, 1],\n",
        "              'max_depth': [3, 5, 7],\n",
        "              'n_estimators': [50, 100, 200],\n",
        "              'subsample': [0.5, 0.75, 1]}\n",
        "\n",
        "    gb = GradientBoostingClassifier()\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(gb, parameters, cv=cv, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator from the GridSearchCV\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    predictions = best_estimator.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nGradient Boost:\\n\")\n",
        "\n",
        "data = [GB(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "52622dac",
      "metadata": {},
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078108e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def LR(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    parameters = {\n",
        "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "        'max_iter': [100, 250, 500],\n",
        "        'class_weight': [None, 'balanced']\n",
        "    }\n",
        "\n",
        "    lr = LogisticRegression(random_state=42)\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(lr, parameters, cv=cv, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator from the GridSearchCV\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    predictions = best_estimator.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nLogistic Regression:\\n\")\n",
        "\n",
        "data = [LR(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2dd7449a",
      "metadata": {},
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681326a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def RF(X,y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    parameters = {\n",
        "        \"n_estimators\": [100, 250, 500],\n",
        "        \"max_depth\": [3, 5, 7],\n",
        "        \"max_features\": [\"sqrt\", \"log2\", 0.5, None],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    rf = RandomForestClassifier()\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(rf, parameters, cv=cv, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator from the GridSearchCV\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    predictions = best_estimator.predict(X_test)\n",
        "\n",
        "    return [str(grid_search.best_params_).replace(',','\\n'), grid_search.best_score_,accuracy_score(y_test, predictions)]\n",
        "\n",
        "print(\"\\nRandom Forest:\\n\")\n",
        "\n",
        "data = [RF(X,y)]\n",
        "head = [\"Parameters\",\"CV score\",\"Accuracy\"]\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt=\"grid\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "12eac538",
      "metadata": {},
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286e9c44",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data(df,month,feature):\n",
        "    df_year = df[df['year'] == 2020]\n",
        "    df_month = df_year[df_year['month'] == month]\n",
        "    return [df_month[feature].mean()]\n",
        "\n",
        "date = 1\n",
        "month = 8\n",
        "year = 2023\n",
        "\n",
        "pred = pd.DataFrame.from_dict({\n",
        "        'date':[date], \n",
        "        'month':[month], \n",
        "        'year':[year],\n",
        "        'temperature':get_data(df,month,'temperature'),\n",
        "        'specific humidity':get_data(df,month,'specific humidity'),\n",
        "        'relative humidity':get_data(df,month,'relative humidity'),\n",
        "        'surface pressure':get_data(df,month,'surface pressure'),\n",
        "        'wind speed':get_data(df,month,'wind speed'),\n",
        "        'wind direction':get_data(df,month,'wind direction')})\n",
        "\n",
        "model = RandomForestClassifier(max_depth=7,max_features=None,min_samples_leaf=1,min_samples_split=5,n_estimators=250)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(pred)\n",
        "\n",
        "if(pred[0]==0):\n",
        "    print(\"Rainfall = 0 mm\")\n",
        "elif(pred[0]==1):\n",
        "    print(\"Rainfall ranges from 0 to 2.5 mm\")\n",
        "elif(pred[0]==2):\n",
        "    print(\"Rainfall ranges from 2.5 to 7.5 mm\")\n",
        "elif(pred[0]==3):\n",
        "    print(\"Rainfall ranges from 7.5 to 35.5 mm\")\n",
        "elif(pred[0]==4):\n",
        "    print(\"Rainfall ranges from 35.5 to 64.4 mm\")\n",
        "elif(pred[0]==5):\n",
        "    print(\"Rainfall ranges from 64.4 to 124.4 mm\")\n",
        "else:\n",
        "    print(\"Rainfall ranges above 124.4 mm\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Python 3.8.10)",
      "language": "python",
      "name": "py371"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
